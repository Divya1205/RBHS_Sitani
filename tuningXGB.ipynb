{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier #GBM algorithm\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = (5, 10)\n",
    "import matlab.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ran=1;%for GBM\n",
    "#ran=35;%for KNN\n",
    "#Please manually change in Matlab code reading_hotspot2Data_v3\n",
    "os.getcwd()\n",
    "os.chdir('/Users/sitani/Desktop/CS_final_codes/workonhotspots/')\n",
    "eng = matlab.engine.start_matlab()\n",
    "eng.reading_hotspot2Data_v4(nargout=0)\n",
    "os.chdir('/Users/sitani/Desktop/CS_final_codes/workonhotspots/FinalCodesForPublication/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.read_csv('Atrain_whole.csv',header=None)\n",
    "y=pd.read_csv('label_whole.csv',header=None)\n",
    "\n",
    "X_train = pd.read_csv('Atrain2.csv',header=None)\n",
    "X_valid = pd.read_csv('Avalid2.csv',header=None)\n",
    "\n",
    "y_train=pd.read_csv('label_train2.csv',header=None)\n",
    "y_valid=pd.read_csv('label_valid2.csv',header=None)\n",
    "\n",
    "X_test=pd.read_csv('Atest2.csv',header=None)\n",
    "y_test=pd.read_csv('label_test2.csv',header=None)\n",
    "\n",
    "X_train=X_train.T#transpose\n",
    "X_valid=X_valid.T\n",
    "X=X.T\n",
    "X_test=X_test.T\n",
    "\n",
    "y_train=y_train.values.ravel()\n",
    "y_valid=y_valid.values.ravel()\n",
    "y=y.values.ravel()\n",
    "y_test=y_test.values.ravel()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    \n",
    "    \n",
    "def modelfit(alg, train_data,train_labels, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(train_data,train_labels)\n",
    "        \n",
    "    #Predict training set:\n",
    "    train_predictions = alg.predict(train_data)\n",
    "    train_predprob = alg.predict_proba(train_data)[:,1]\n",
    "    \n",
    "    #Perform cross-validation:\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(train_data, label=train_labels)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "     #Fit the algorithm on the data\n",
    "    alg.fit(train_data,train_labels,eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(train_data)\n",
    "    dtrain_predprob = alg.predict_proba(train_data)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(train_labels, dtrain_predictions))\n",
    "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(train_labels, dtrain_predprob))\n",
    "    plt.rcParams['figure.figsize'] = [15,15]               \n",
    "    feat_imp = pd.Series(alg.feature_importances_,predictors).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in X.columns ]\n",
    "xgb1 = XGBClassifier(learning_rate =0.5,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, X,y, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rounds=2\n",
    "param_test1 = {\n",
    " 'max_depth':np.arange(3,10,3),\n",
    " 'min_child_weight':np.arange(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.5, n_estimators=10,max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(X,y)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[4,5,6],\n",
    " 'min_child_weight':[4,5,6]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(X,y)\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test2b = {\n",
    " 'min_child_weight':[6,8,10,12]\n",
    "}\n",
    "gsearch2b = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=4,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2b, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2b.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfit(gsearch3.best_estimator_,X,y,predictors)\n",
    "gsearch2b.grid_scores_, gsearch2b.best_params_, gsearch2b.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=gsearch2.best_params_['max_depth'],\n",
    " min_child_weight=gsearch2b.best_params_['min_child_weight'], gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(X,y)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb2 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=gsearch2.best_params_['max_depth'],\n",
    " min_child_weight=gsearch2.best_params_['min_child_weight'],\n",
    " gamma=gsearch3.best_params_['gamma'],\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb2, X,y, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=gsearch2.best_params_['max_depth'],\n",
    " min_child_weight=gsearch2.best_params_['min_child_weight'], gamma=gsearch3.best_params_['gamma'], subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(X,y)\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test5 = {\n",
    " 'subsample':[i/100.0 for i in range(75,90,5)],\n",
    " 'colsample_bytree':[i/100.0 for i in range(75,90,5)]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=gsearch2.best_params_['max_depth'],\n",
    " min_child_weight=gsearch2.best_params_['min_child_weight'], gamma=gsearch3.best_params_['gamma'], subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(X,y)\n",
    "gsearch5.grid_scores_, gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test6 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=gsearch2.best_params_['max_depth'],\n",
    " min_child_weight=gsearch2.best_params_['min_child_weight'],gamma=gsearch3.best_params_['gamma'], \n",
    "subsample=gsearch5.best_params_['subsample'], colsample_bytree=gsearch5.best_params_['colsample_bytree'],\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test6, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch6.fit(X,y)\n",
    "gsearch6.grid_scores_, gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test7 = {\n",
    " 'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05]\n",
    "}\n",
    "gsearch7 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177,\n",
    "max_depth=gsearch2.best_params_['max_depth'],min_child_weight=gsearch2.best_params_['min_child_weight'],\n",
    "gamma=gsearch3.best_params_['gamma'],subsample=gsearch5.best_params_['subsample'], \n",
    "colsample_bytree=gsearch5.best_params_['colsample_bytree'], objective= 'binary:logistic', nthread=4, \n",
    "scale_pos_weight=1,seed=27), param_grid = param_test7, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch7.fit(X,y)\n",
    "gsearch7.grid_scores_, gsearch7.best_params_, gsearch7.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb3 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=gsearch2.best_params_['max_depth'],min_child_weight=gsearch2.best_params_['min_child_weight'],\n",
    "gamma=gsearch3.best_params_['gamma'],subsample=gsearch5.best_params_['subsample'], \n",
    "colsample_bytree=gsearch5.best_params_['colsample_bytree'],\n",
    " reg_alpha=gsearch7.best_params_['alpha'],\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb3,X,y, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb4 = XGBClassifier(\n",
    " learning_rate =0.01,\n",
    " n_estimators=5000,\n",
    " max_depth=gsearch2.best_params_['max_depth'],min_child_weight=gsearch2.best_params_['min_child_weight'],\n",
    "gamma=gsearch3.best_params_['gamma'],subsample=gsearch5.best_params_['subsample'], \n",
    "colsample_bytree=gsearch5.best_params_['colsample_bytree'],\n",
    " reg_alpha=gsearch7.best_params_['alpha'],\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb4, X,y, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "#import pdb\n",
    "#pdb.set_trace()\n",
    "model=xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=90,\n",
    "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=5,\n",
    "       reg_alpha=1, reg_lambda=0.1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "#import pdb\n",
    "#pdb.set_trace()\n",
    "model=xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=90,\n",
    "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=5,\n",
    "       reg_alpha=1, reg_lambda=0.1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)\n",
    "model.fit(X,y)\n",
    "model.score(X_test,y_test)\n",
    "y_test_pred = model.predict(X_test) \n",
    "svm_roc_auc = roc_auc_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "print('Accuracy of GTB classifier: {:.2f}'.format(model.score(X_test, y_test)))\n",
    "print('\\n')\n",
    "confusion_df = pd.DataFrame(confusion_matrix(y_test,y_test_pred),\n",
    "             columns=[\"Predicted Class \" + str(class_name) for class_name in [1,0]],\n",
    "             index = [\"Class \" + str(class_name) for class_name in [1,0]])\n",
    "\n",
    "print('Confusion matrix : \\n',confusion_df.T)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "cm1 = confusion_matrix(y_test, y_test_pred).T\n",
    "print('\\n')\n",
    "total1=sum(sum(cm1))\n",
    "print(cm1)\n",
    "#####from confusion matrix calculate sensitivity specificity\n",
    "\n",
    "tn=confusion_matrix(y_test, y_test_pred)[0, 0]\n",
    "fp=confusion_matrix(y_test, y_test_pred)[0, 1]\n",
    "fn=confusion_matrix(y_test, y_test_pred)[1, 0]\n",
    "tp=confusion_matrix(y_test, y_test_pred)[1, 1]\n",
    "#sensitivity1=tp/(tp+fn)\n",
    "\n",
    "#print('Sensitivity :', sensitivity1 )\n",
    "#print('\\n')\n",
    "\n",
    "specificity=tn/(tn+fp)\n",
    "print('Specificity :', specificity)\n",
    "print('\\n')\n",
    "#precision=tp/(tp+fp)\n",
    "#precision = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "#print('precision :', precision)\n",
    "#print('\\n')\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"Precision score: {}\".format(precision_score(y_test,y_test_pred)))\n",
    "print('\\n')\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Recall or Sensitivity: {}\".format(recall_score(y_test,y_test_pred)))\n",
    "print('\\n')\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"F1 Score: {}\".format(f1_score(y_test,y_test_pred)))\n",
    "print('\\n')\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "print(\"Matthews Correlation Coefficient: {}\".format(matthews_corrcoef(y_test, y_test_pred)))\n",
    "print('\\n')\n",
    "##Area under Curve-AUC\n",
    "auc = roc_auc_score(y_test, gbm_tuned_1.predict_proba(X_test)[:,1])\n",
    "print('AUC: %.3f' % auc)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "confusion_df = pd.DataFrame(confusion_matrix(y_test,final_pred),\n",
    "             columns=[\"Predicted Class \" + str(class_name) for class_name in [0,1]],\n",
    "             index = [\"Class \" + str(class_name) for class_name in [0,1]])\n",
    "\n",
    "print('Confusion matrix : \\n',confusion_df)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "cm1 = confusion_matrix(y_test, final_pred)\n",
    "print('\\n')\n",
    "total1=sum(sum(cm1))\n",
    "\n",
    "#####from confusion matrix calculate sensitivity specificity\n",
    "\n",
    "accuracy1=(cm1[0,0]+cm1[1,1])/total1\n",
    "print('Accuracy :', accuracy1)\n",
    "print('\\n')\n",
    "sensitivity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print('Sensitivity :', sensitivity1 )\n",
    "print('\\n')\n",
    "specificity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print('Specificity :', specificity1)\n",
    "print('\\n')\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"Precision score: {}\".format(precision_score(y_test,final_pred)))\n",
    "print('\\n')\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"F1 Score: {}\".format(f1_score(y_test,final_pred)))\n",
    "print('\\n')\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "print(\"Matthews Correlation Coefficient: {}\".format(matthews_corrcoef(y_test, final_pred)))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
